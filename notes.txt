PROBLEMS?

	Y is flat 1 x N array
	generally use flat array instead of one row arrays ([0] vs [[0]])
	  or column vectors
	predictions are returned as columns
	python indices start at 0, matlab indices start at 1;
	  inconsistent use of both in these tools 
	FIXED(?): some classifiers can't be retrained, must instantiate new object 
	FIXED(?): train methods don't have default args
	.T notation doesn't work on flat arrays

GENERAL TODOs:

	next steps:
		DONE: finish and test bagged classifier
		implement and test logisticMseClassify
		implement and test nnetClassify
		DONE: implement and test knnRegress
		DONE: implement and test linearRegress
		DONE: implement and test treeRegress
		DONE: implement and test baggedRegress
		implement and test nnetRegress

	fix auc/roc, retest
	fix linreg option in linear classifier and test
	test train_soft in linear/logistic classifier
	make sure all methods implemented/retest
	implement nnetClassify 
	test tree classier training options 
	DONE: change range to permutation (grep 'np.random.permutation' *) and retest
	add plotting 
	fix LogisticRegress
	fix BaggedClassify train method
	DONE: fix BaggedClassify __setitem__
	
	upon finish:
 		add Ihler's comments 
		execute comprehensive tests
		ensure consistency of doc strings
		DONE: fix indentation in regressors
		arg error checking

	optional?
		modularize __dectree_train in tree classifer
		DONE(?): make sure inheritance is optimally utilized while maintaing clarity (added to_1_of_K to Classify)
